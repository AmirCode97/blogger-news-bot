
import os
import requests
from bs4 import BeautifulSoup
from datetime import datetime
import google.generativeai as genai
from blogger_poster import BloggerPoster
from dotenv import load_dotenv
import json

# Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ù…ØªØºÛŒØ±Ù‡Ø§
load_dotenv()

# ØªÙ†Ø¸ÛŒÙ…Ø§Øª Ø®Ø¨Ø± Ø®Ø§Øµ
TARGET_URL = "https://eutoday.net/iran-irgc-and-the-end-of-europes-strategic-patience/"

# Ø¨ÛŒÙˆÚ¯Ø±Ø§ÙÛŒ ÙØ§Ø±Ø³ÛŒ
AUTHOR_BIO_FA = """
<hr>
<div style="background-color: #f9f9f9; padding: 20px; border-right: 5px solid #2c3e50; margin-top: 30px;">
    <div style="display: flex; align-items: center; margin-bottom: 15px;">
        <h3 style="margin: 0; color: #2c3e50; font-family: Tahoma, sans-serif;">Ø¯Ø±Ø¨Ø§Ø±Ù‡ Ù†ÙˆÛŒØ³Ù†Ø¯Ù‡: Ø­Ø³ÛŒÙ† Ø§Ù…Ø¬Ø¯ÛŒ</h3>
    </div>
    <p style="text-align: justify; font-size: 0.95em; line-height: 1.8; font-family: Tahoma, sans-serif;">
        Ø­Ø³ÛŒÙ† Ø§Ù…Ø¬Ø¯ÛŒØŒ ÙØ¹Ø§Ù„ Ø­Ù‚ÙˆÙ‚ Ø¨Ø´Ø± Ø§ÛŒØ±Ø§Ù†ÛŒ Ø³Ø§Ú©Ù† Ø§ÙˆØ¨Ø±Ù‡Ø§ÙˆØ²Ù† Ø¢Ù„Ù…Ø§Ù† Ùˆ Ø¹Ø¶Ùˆ Ø§Ù†Ø¬Ù…Ù† <strong>VVMIran e.V.</strong> (Ø§Ù†Ø¬Ù…Ù† Ø¯ÙØ§Ø¹ Ø§Ø² Ø­Ù‚ÙˆÙ‚ Ø¨Ø´Ø± Ø¯Ø± Ø§ÛŒØ±Ø§Ù†) Ø§Ø³Øª. 
        Ø§Ùˆ Ù¾Ø³ Ø§Ø² Ù…ÙˆØ§Ø¬Ù‡Ù‡ Ø¨Ø§ ØªÙ‡Ø¯ÛŒØ¯Ø§Øª Ø¬Ø¯ÛŒ Ø¬Ø§Ù†ÛŒØŒ Ù…Ø¬Ø¨ÙˆØ± Ø¨Ù‡ ØªØ±Ú© Ø§ÛŒØ±Ø§Ù† Ø´Ø¯. ØªÙ…Ø±Ú©Ø² Ù†ÙˆØ´ØªÙ‡â€ŒÙ‡Ø§ÛŒ Ø§Ùˆ Ø¨Ø± Ø³Ø±Ú©ÙˆØ¨ Ø¯ÙˆÙ„ØªÛŒØŒ Ù‡Ø¯Ù Ù‚Ø±Ø§Ø± Ú¯Ø±ÙØªÙ† Ø¨Ø§Ø²Ø¯Ø§Ø´Øªâ€ŒØ´Ø¯Ú¯Ø§Ù† Ùˆ Ù…Ø¹ØªØ±Ø¶Ø§Ù†ØŒ Ùˆ ÙˆØ¶Ø¹ÛŒØª Ø²Ù†Ø§Ù† Ø¯Ø± Ø§ÛŒØ±Ø§Ù† Ø§Ø³Øª.
    </p>
    <p style="text-align: justify; font-size: 0.95em; line-height: 1.8; font-family: Tahoma, sans-serif;">
        Ø§Ù…Ø¬Ø¯ÛŒ Ù‡Ù…Ú†Ù†ÛŒÙ† Ù…Ù‡Ù†Ø¯Ø³ Ù†Ø±Ù…â€ŒØ§ÙØ²Ø§Ø± Ø¨Ø§ ØªØ®ØµØµ Ø¯Ø± Ø²ÛŒØ±Ø³Ø§Ø®Øªâ€ŒÙ‡Ø§ÛŒ Ø­ÛŒØ§ØªÛŒ Ø§Ø³Øª Ùˆ Ù¾Ú˜ÙˆÙ‡Ø´â€ŒÙ‡Ø§ÛŒ Ø§Ùˆ Ø¨Ø± Ø´Ù†Ø§Ø³Ø§ÛŒÛŒ Ø´Ø¨Ú©Ù‡â€ŒÙ‡Ø§ÛŒ ÙÙ†ÛŒ Ùˆ Ù…Ø§Ù„ÛŒ Ú©Ù‡ Ø§Ù…Ú©Ø§Ù† Ø³Ø±Ú©ÙˆØ¨ ÙØ±Ø§Ù…Ù„ÛŒ Ø±Ø§ Ø¨Ø±Ø§ÛŒ Ø±Ú˜ÛŒÙ… ÙØ±Ø§Ù‡Ù… Ù…ÛŒâ€ŒÚ©Ù†Ù†Ø¯ØŒ Ù…ØªÙ…Ø±Ú©Ø² Ù…ÛŒâ€ŒØ¨Ø§Ø´Ø¯.
    </p>
</div>
"""

def fetch_article_content(url):
    print(f"ğŸŒ Fetching article from: {url}")
    headers = {
        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'
    }
    try:
        response = requests.get(url, headers=headers, timeout=15)
        response.raise_for_status()
        soup = BeautifulSoup(response.content, 'html.parser')
        
        # Ø§Ø³ØªØ®Ø±Ø§Ø¬ ØªÛŒØªØ±
        title_tag = soup.find('h1')
        title = title_tag.get_text().strip() if title_tag else "News Article"
        
        # Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ù…ØªÙ† Ø§ØµÙ„ÛŒ
        article_body = soup.find('article') or soup.find('div', class_='entry-content') or soup.find('div', class_='post-content')
        
        paragraphs = []
        if article_body:
            for p in article_body.find_all('p'):
                text = p.get_text().strip()
                if len(text) > 20:
                    paragraphs.append(text)
        
        full_text = "\n\n".join(paragraphs)
        
        # Ø§Ø³ØªØ®Ø±Ø§Ø¬ ØªØµÙˆÛŒØ± Ø§ØµÙ„ÛŒ
        image_url = None
        img_tag = soup.find('meta', property='og:image')
        if img_tag:
            image_url = img_tag.get('content')
            
        print(f"âœ… Fetched: {title}")
        return {
            "title": title,
            "link": url,
            "full_content": full_text,
            "image_url": image_url,
            "source": "EU Today",
            "fetched_at": datetime.now().isoformat()
        }
    except Exception as e:
        print(f"âŒ Error fetching article: {e}")
        return None

def process_and_post_manual():
    # 1. Ø¯Ø±ÛŒØ§ÙØª Ù…Ù‚Ø§Ù„Ù‡
    article = fetch_article_content(TARGET_URL)
    if not article:
        return

    # 2. Ø±Ø§Ù‡ Ø§Ù†Ø¯Ø§Ø²ÛŒ Ú©Ù„Ø§ÛŒÙ†Øª Ø¨Ù„Ø§Ú¯Ø±
    try:
        poster = BloggerPoster()
        if not poster.service:
            print("âŒ Blogger API auth failed")
            return
    except Exception as e:
        print(f"âŒ Error initializing BloggerPoster: {e}")
        return

    # 3. Ù¾Ø±Ø¯Ø§Ø²Ø´ (Ø¨Ø¯ÙˆÙ† Ù‡ÙˆØ´ Ù…ØµÙ†ÙˆØ¹ÛŒ Ø¨Ù‡ Ø¯Ù„ÛŒÙ„ Ø§Ù†Ù‚Ø¶Ø§ÛŒ Ú©Ù„ÛŒØ¯)
    print("âš ï¸ AI API Expired. Using original content...")
    
    fa_title = article['title']
    # ØªØ¨Ø¯ÛŒÙ„ Ù…ØªÙ† Ø³Ø§Ø¯Ù‡ Ø¨Ù‡ Ù¾Ø§Ø±Ø§Ú¯Ø±Ø§Ùâ€ŒÙ‡Ø§ÛŒ HTML
    article_paragraphs = article['full_content'].split('\n\n')
    fa_body = "".join([f"<p>{p}</p>" for p in article_paragraphs])
    
    # 4. Ø§ÙØ²ÙˆØ¯Ù† ØªØµÙˆÛŒØ±
    final_html = ""
    if article['image_url']:
        final_html += f'<div class="separator" style="clear: both; text-align: center;"><img border="0" src="{article["image_url"]}" style="display: block; padding: 1em 0; text-align: center; width: 100%; max-width: 800px;" /></div><br/>'
    
    final_html += fa_body
    
    # 5. Ø§ÙØ²ÙˆØ¯Ù† Ø¨ÛŒÙˆÚ¯Ø±Ø§ÙÛŒ Ù†ÙˆÛŒØ³Ù†Ø¯Ù‡
    final_html += "<br><br>" + AUTHOR_BIO_FA
    
    # 6. Ø§Ù†ØªØ´Ø§Ø± Ø¯Ø± Ø¨Ù„Ø§Ú¯Ø±
    print(f"ğŸš€ Publishing: {fa_title}")
    
    body = {
        "kind": "blogger#post",
        "blog": {"id": os.getenv("BLOG_ID")},
        "title": fa_title,
        "content": final_html,
        "labels": ["Ø®Ø¨Ø± ÙÙˆØ±ÛŒ", "Ú¯Ø²Ø§Ø±Ø´ ÙˆÛŒÚ˜Ù‡", "Ø¨ÛŒÙ†â€ŒØ§Ù„Ù…Ù„Ù„", "Ø­Ø³ÛŒÙ† Ø§Ù…Ø¬Ø¯ÛŒ", "English"]
    }
    
    try:
        posts = poster.service.posts()
        result_post = posts.insert(blogId=os.getenv("BLOG_ID"), body=body, isDraft=False).execute()
        print(f"âœ… Successfully published! URL: {result_post.get('url')}")
    except Exception as e:
        print(f"âŒ Error during posting: {e}")

if __name__ == "__main__":
    process_and_post_manual()
